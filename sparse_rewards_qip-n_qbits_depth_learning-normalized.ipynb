{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyclifford as pc\n",
    "import gymnasium as gym\n",
    "import stable_baselines3\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyclifford as pc\n",
    "from pyclifford.utils import mask, condense, pauli_diagonalize1,stabilizer_measure\n",
    "from pyclifford.paulialg import Pauli, pauli, PauliMonomial, pauli_zero\n",
    "from pyclifford.stabilizer import (StabilizerState, CliffordMap,\n",
    "    zero_state, identity_map, clifford_rotation_map, random_clifford_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_layers(N_QUBITS,HALF_DEPTH):\n",
    "    random_layers=[]\n",
    "    for i in range (int(HALF_DEPTH)):\n",
    "        random_layer=[]\n",
    "        if i%2==0:\n",
    "            for j in range (int(np.floor(N_QUBITS/2))):\n",
    "                gate=pc.CliffordGate(j*2,j*2+1)\n",
    "                gate.set_forward_map(pc.random_clifford_map(2))\n",
    "                random_layer.append(gate)\n",
    "            random_layers.append(random_layer)\n",
    "        elif i%2==1:\n",
    "            for j in range (int(np.floor(N_QUBITS/2))):\n",
    "                gate=pc.CliffordGate(j*2+1,(j*2+2)%N_QUBITS)\n",
    "                gate.set_forward_map(pc.random_clifford_map(2))\n",
    "                random_layer.append(gate)\n",
    "            random_layers.append(random_layer)\n",
    "    return random_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_layers(N_QUBITS,HALF_DEPTH,theta):\n",
    "    measure_layers=[]\n",
    "    for i in range (int(HALF_DEPTH)):\n",
    "        measure_layer=[]\n",
    "        for j in range (int(N_QUBITS)):\n",
    "            if theta[-i + HALF_DEPTH - 1][j]==1:\n",
    "                measure_layer.append(j)\n",
    "        measure_layers.append(measure_layer)\n",
    "    return measure_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_circuit(N_QUBITS,HALF_DEPTH,random_layers,measure_layers):\n",
    "    circ = pc.circuit.Circuit(N_QUBITS)\n",
    "    for i in range(int(HALF_DEPTH)):\n",
    "        for j in range(int(np.floor(N_QUBITS/2))):\n",
    "            circ.take(random_layers[i][j])\n",
    "        if measure_layers[i]!=[]:\n",
    "            qubits=tuple(measure_layers[i])\n",
    "            circ.measure(*qubits)\n",
    "            \n",
    "    return circ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_EE(state_final):\n",
    "    EE_positions=[]\n",
    "    for i in range(0,state_final.N):\n",
    "        EE_positions.append([int(i),int(i+1)%state_final.N])\n",
    "        \n",
    "    EE_list=[]\n",
    "    for i in range(0,len(EE_positions)):\n",
    "        EE_list.append(state_final.entropy(EE_positions[i]))\n",
    "    \n",
    "    averaged_EE=np.mean(EE_list)\n",
    "        \n",
    "    return averaged_EE #, EE_positions, EE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty(x,penalty_slope):\n",
    "    return 2*(0.5-(1/(1+np.exp(-penalty_slope*x))-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Disentangler(gym.Env):\n",
    "    \"\"\"\n",
    "    Reinforcement learning environment for the disentangler.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits, half_depth, positive_reward, penalty_slope):\n",
    "        super(Disentangler, self).__init__()\n",
    "        \n",
    "        self.N_QUBITS = n_qubits\n",
    "        self.HALF_DEPTH = half_depth\n",
    "        self.DEPTH = 2*half_depth\n",
    "        #self.positive_reward = positive_reward\n",
    "        self.penalty_slope = penalty_slope\n",
    "        \n",
    "        self.action_space = gym.spaces.Discrete(self.N_QUBITS * self.HALF_DEPTH)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(self.HALF_DEPTH, self.N_QUBITS), dtype=np.int8)\n",
    "\n",
    "        self.random_layers=random_layers(self.N_QUBITS,self.HALF_DEPTH)\n",
    "        self.theta = np.zeros((self.HALF_DEPTH, self.N_QUBITS), dtype=np.int8)\n",
    "        self.measure_layers=measure_layers(self.N_QUBITS,self.HALF_DEPTH,self.theta)\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Initialize reward and done\n",
    "        reward = 0\n",
    "        done = False\n",
    "        truncate = False\n",
    "\n",
    "        # Apply the action\n",
    "        h = np.zeros(self.N_QUBITS * self.HALF_DEPTH, dtype=np.int8)\n",
    "        h[action] = 1\n",
    "        h = h.reshape((self.HALF_DEPTH, self.N_QUBITS))\n",
    "        self.theta = (self.theta + h) % 2\n",
    "\n",
    "        # Calculate entropy (assumes circuit is a predefined function)\n",
    "        self.measure_layers=measure_layers(self.N_QUBITS, self.HALF_DEPTH, self.theta)\n",
    "        circ = create_circuit(self.N_QUBITS, self.HALF_DEPTH, self.random_layers, self.measure_layers)\n",
    "\n",
    "        state_initial = pc.stabilizer.zero_state(self.N_QUBITS)\n",
    "        state_final = circ.forward(state_initial)\n",
    "\n",
    "        entropy = averaged_EE(state_final)\n",
    "\n",
    "        \n",
    "        if entropy == 0:\n",
    "            m_per_layer = [np.sum(layer) for layer in self.theta]\n",
    "            cost = [m_per_layer[i]*penalty(i,self.penalty_slope) for i in range(self.HALF_DEPTH)]\n",
    "            penalty_list=[penalty(i,self.penalty_slope) for i in range(self.HALF_DEPTH)]\n",
    "            reward = 1 - sum(cost)/(self.N_QUBITS*sum(penalty_list))\n",
    "            #reward = self.positive_reward - np.sum(cost)/(self.N_QUBITS*self.DEPTH)\n",
    "            done = True\n",
    "        \n",
    "        # Return the state, reward, done flag, truncate flag, and info\n",
    "        info = {}\n",
    "        return self.theta, reward, done, truncate, info\n",
    "    \n",
    "    def return_entropy(self):\n",
    "        # Calculate entropy (assumes circuit is a predefined function)\n",
    "        self.measure_layers=measure_layers(self.N_QUBITS, self.HALF_DEPTH, self.theta)\n",
    "        circ = create_circuit(self.N_QUBITS, self.HALF_DEPTH, self.random_layers, self.measure_layers)\n",
    "\n",
    "        state_initial = pc.stabilizer.zero_state(self.N_QUBITS)\n",
    "        state_final = circ.forward(state_initial)\n",
    "\n",
    "        entropy = averaged_EE(state_final)\n",
    "        \n",
    "        return entropy\n",
    "        \n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        # Seed the random number generator if a seed is provided\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # Reset the state to an all-zero matrix\n",
    "        self.theta = np.zeros((self.HALF_DEPTH, self.N_QUBITS), dtype=np.int8)\n",
    "\n",
    "        # Reset the random layers to another random layers\n",
    "        self.random_layers=random_layers(self.N_QUBITS,self.HALF_DEPTH)\n",
    "        \n",
    "        info = {}\n",
    "        return self.theta, info\n",
    "    \n",
    "    def render(self):\n",
    "        print()\n",
    "\n",
    "    def close(self):\n",
    "        # Optional: Implement any cleanup\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppo parameters\n",
    "ts = 0.5*1e6\n",
    "lr = 0.001\n",
    "ec = 0.01\n",
    "#ec_list=[0.01,0.1,0.2,0.3,0.4,0.5,1,2,3,4,5]\n",
    "\n",
    "# circuit parameters\n",
    "#N_QUBITS=10\n",
    "N_QUBITS_list=[10]#[2,3,4,5,6,7,8,9,10]#,15,20,25,30]\n",
    "\n",
    "#HALF_DEPTH=2\n",
    "#DEPTH=int(2*HALF_DEPTH)\n",
    "HALF_DEPTH_list=[30]#[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "DEPTH_list=[int(2*HALF_DEPTH_list[i]) for i in range(np.size(HALF_DEPTH_list))]\n",
    "\n",
    "positive_reward = 50\n",
    "penalty_slope = 0#[0,0.5,1,2,3,4,5]\n",
    "\n",
    "#num_full_learning = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_QUBITS = 10\n",
      "HALF_DEPTH = 30\n"
     ]
    }
   ],
   "source": [
    "#This part is to check the stability of learning\n",
    "#model_set=[[] for i in range(np.size(HALF_DEPTH_list))]\n",
    "\n",
    "for i in range(np.size(N_QUBITS_list)):\n",
    "    N_QUBITS = N_QUBITS_list[i]\n",
    "    print(\"N_QUBITS\",'=',N_QUBITS)\n",
    "    for j in range(np.size(HALF_DEPTH_list)):\n",
    "        HALF_DEPTH = HALF_DEPTH_list[j]\n",
    "        print(\"HALF_DEPTH\",'=',HALF_DEPTH)\n",
    "        env = Disentangler(N_QUBITS,HALF_DEPTH,positive_reward,penalty_slope)\n",
    "\n",
    "        env.reset()\n",
    "        model = PPO('MlpPolicy', env, verbose=0, tensorboard_log=\"./tensorboard_files\", learning_rate=lr, ent_coef=ec)\n",
    "\n",
    "        model.learn(total_timesteps=ts, tb_log_name=\"{N_QUBITS}x{HALF_DEPTH}_tb_{ts}_pr_{positive_reward}_ps_{penalty_slope}\".format(N_QUBITS=N_QUBITS, HALF_DEPTH=HALF_DEPTH, ts=ts, positive_reward=positive_reward, penalty_slope=penalty_slope))\n",
    "        model_path = \"./models/{N_QUBITS}x{HALF_DEPTH}_tb_{ts}_pr_{positive_reward}_ps_{penalty_slope}\".format(N_QUBITS=N_QUBITS, HALF_DEPTH=HALF_DEPTH, ts=ts, positive_reward=positive_reward, penalty_slope=penalty_slope)\n",
    "        #model_set[i].append(model_path)\n",
    "        model.save(model_path)\n",
    "        print(\"learning done\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6582573641864072,\n",
       " array([[1, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       "        [0, 0, 1, 0, 1, 1, 0, 0, 1, 0],\n",
       "        [1, 1, 1, 0, 1, 0, 1, 0, 1, 1],\n",
       "        [1, 0, 1, 1, 0, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 1, 0, 1, 1, 0, 1],\n",
       "        [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 0, 0, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HALF_DEPTH = 10\n",
    "penalty_slope=2\n",
    "\n",
    "theta =np.random.randint(2, size=(N_QUBITS,HALF_DEPTH))\n",
    "\n",
    "m_per_layer = [np.sum(layer) for layer in theta]\n",
    "cost = [m_per_layer[i]*penalty(i,penalty_slope) for i in range(HALF_DEPTH)]\n",
    "\n",
    "x=range(HALF_DEPTH)\n",
    "penalty_list=[penalty(i,penalty_slope) for i in range(HALF_DEPTH)]\n",
    "reward = 1 - sum(cost)/(N_QUBITS*sum(penalty_list))\n",
    "\n",
    "plt.scatter(x,penalty_list)\n",
    "reward,theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
